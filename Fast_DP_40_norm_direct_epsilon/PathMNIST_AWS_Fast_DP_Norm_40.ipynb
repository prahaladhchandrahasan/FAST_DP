{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xNlVEXvQLUa_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "device = \"cuda\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
        "import torchvision\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as tt\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import CIFAR10, ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import random_split, DataLoader, Subset, TensorDataset, Dataset\n",
        "from torch.nn.utils import vector_to_parameters, parameters_to_vector\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/awslabs/fast-differential-privacy.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCm7_IVxPUou",
        "outputId": "4b641d18-b0f0-49e1-9830-b7458e4886b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fast-differential-privacy'...\n",
            "remote: Enumerating objects: 857, done.\u001b[K\n",
            "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 857 (delta 134), reused 89 (delta 89), pack-reused 698 (from 1)\u001b[K\n",
            "Receiving objects: 100% (857/857), 833.28 KiB | 2.59 MiB/s, done.\n",
            "Resolving deltas: 100% (574/574), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fast-differential-privacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG3OSjtQPZMa",
        "outputId": "bb5aa431-da1e-4a82-ea19-57d015bdb09b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fast-differential-privacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m setup develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SKSYdV9Plhb",
        "outputId": "2a94e62f-1da5-4e58-a828-1f31d9ab2fbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fast-differential-privacy\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:41: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating fastDP.egg-info\n",
            "writing fastDP.egg-info/PKG-INFO\n",
            "writing dependency_links to fastDP.egg-info/dependency_links.txt\n",
            "writing top-level names to fastDP.egg-info/top_level.txt\n",
            "writing manifest file 'fastDP.egg-info/SOURCES.txt'\n",
            "reading manifest file 'fastDP.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "adding license file 'NOTICE.md'\n",
            "writing manifest file 'fastDP.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.10/dist-packages/fastDP.egg-link (link to .)\n",
            "Adding fastDP 2.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/fast-differential-privacy\n",
            "Processing dependencies for fastDP==2.0.0\n",
            "Finished processing dependencies for fastDP==2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmgCKjjsLhSq",
        "outputId": "a6a4c8d2-a1db-4054-97a0-69b2cea34f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TPJo4tZcLvik"
      },
      "outputs": [],
      "source": [
        "class PathMNIST(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 split='train',\n",
        "                 transforms=None,\n",
        "                 target_transform=None,\n",
        "                 download=False):\n",
        "        ''' dataset\n",
        "        :param split: 'train', 'val' or 'test', select subset\n",
        "        :param transform: data transformation\n",
        "        :param target_transform: target transformation\n",
        "\n",
        "        '''\n",
        "\n",
        "        npz_file = np.load(\"/content/drive/MyDrive/ISPP_Folder/pathmnist.npz\")\n",
        "\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        self.transform_index = 0\n",
        "        self.target_transform = target_transform\n",
        "        #X = np.concatenate((npz_file['train_images'], npz_file['val_images']))\n",
        "        #Y = np.concatenate((npz_file['train_labels'], npz_file['val_labels']))\n",
        "        X_train = npz_file['train_images']\n",
        "        Y_train = npz_file['train_labels']\n",
        "        X_val = npz_file['val_images']\n",
        "        Y_val = npz_file['val_labels']\n",
        "        X_test = npz_file['test_images']\n",
        "        Y_test = npz_file['test_labels']\n",
        "        #print(X.shape)\n",
        "        #X_train, X_val,Y_train,Y_val = train_test_split(X,Y,test_size = 0.2, random_state =0 )\n",
        "        print(X_train.shape)\n",
        "        print(X_val.shape)\n",
        "        print(X_test.shape)\n",
        "        if self.split == 'train':  # 89996 images\n",
        "            self.img = X_train\n",
        "            self.label = Y_train\n",
        "        elif self.split == 'val':     #10004  images\n",
        "            self.img = X_val\n",
        "            self.label = Y_val\n",
        "        elif self.split == 'test':      #7180 images\n",
        "            self.img = X_test\n",
        "            self.label = Y_test\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.img[index], self.label[index].astype(int)[0]\n",
        "        img = Image.fromarray(np.uint8(img))\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms[self.transform_index](img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.img.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ylilaOuVjUmX"
      },
      "outputs": [],
      "source": [
        "light_transform = tt.Compose([\n",
        "                              tt.ToTensor(),\n",
        "                              tt.Lambda(lambda x : (x - x.mean())/(x.std()))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzlyWSPRjbTM",
        "outputId": "c94b4ab6-2191-4381-a1a3-279891fe23d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(89996, 28, 28, 3)\n",
            "(10004, 28, 28, 3)\n",
            "(7180, 28, 28, 3)\n",
            "(89996, 28, 28, 3)\n",
            "(10004, 28, 28, 3)\n",
            "(7180, 28, 28, 3)\n",
            "(89996, 28, 28, 3)\n",
            "(10004, 28, 28, 3)\n",
            "(7180, 28, 28, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_ds = PathMNIST(split='train', transforms= [light_transform])\n",
        "val_ds = PathMNIST(split='val', transforms= [light_transform])\n",
        "test_ds = PathMNIST(split='test', transforms= [light_transform])\n",
        "train_dl = DataLoader(train_ds,512,shuffle = True,num_workers = 4, pin_memory = True)\n",
        "test_dl = DataLoader(test_ds,512,True,num_workers = 4, pin_memory = True)\n",
        "val_dl = DataLoader(val_ds,512,True,num_workers = 4, pin_memory = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw0633S2Qqw8",
        "outputId": "58e18978-49b0-4157-bcd9-3d2f5ce94e79"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.13.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->opacus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n",
            "Downloading opacus-1.5.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.9/239.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opacus\n",
            "Successfully installed opacus-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastDP import PrivacyEngine\n",
        "import torch\n",
        "import torchvision\n",
        "torch.manual_seed(2)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "from tqdm import tqdm\n",
        "import warnings; warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "788kwcOWQh-b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WGCCUVPXMA1u"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 512\n",
        "device = 'cuda'\n",
        "NUM_CLASSES = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W2F-jHG8Zxxo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        # Define conv1\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        # Define bn1 (GroupNorm with 2 groups for in_channels channels)\n",
        "       # self.gn1 = nn.GroupNorm(2, in_channels, eps=1e-05, affine=True)\n",
        "        # Define ReLU activation\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # Define conv2\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        # Define bn2 (GroupNorm with 2 groups for out_channels channels)\n",
        "        self.gn2 = nn.GroupNorm(2, out_channels, eps=1e-05, affine=True)\n",
        "        # Define downsample\n",
        "        self.downsample = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
        "            nn.GroupNorm(32, out_channels, eps=1e-05, affine=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through conv1, bn1, and relu\n",
        "        out = self.conv1(x)\n",
        "       # out = self.gn1(out)\n",
        "        out = self.relu(out)\n",
        "        # Forward pass through conv2 and bn2\n",
        "        out = self.conv2(out)\n",
        "        out = self.gn2(out)\n",
        "\n",
        "        # Downsampling path\n",
        "        residual = self.downsample(x)\n",
        "\n",
        "        # Add residual to the output\n",
        "        out += residual\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.gn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.gn2(out)\n",
        "\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7K7T-R-MCvzd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResNet_Part1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet_Part1, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.GroupNorm(32, 64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Layer 1\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
        "            nn.GroupNorm(2, 64, eps=1e-5, affine=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
        "            nn.GroupNorm(2, 64, eps=1e-5, affine=True),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
        "            nn.GroupNorm(2, 64, eps=1e-5, affine=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
        "            nn.GroupNorm(2, 64, eps=1e-5, affine=True))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h8vHLC_2b2Ww"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResNet_Part2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet_Part2, self).__init__()\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wM7MtR0PcW6a"
      },
      "outputs": [],
      "source": [
        "class FullResNet(nn.Module):\n",
        "    def __init__(self, model_part1, model_layer2, model_layer3, model_layer4, model_part2):\n",
        "        super(FullResNet, self).__init__()\n",
        "        # Store each part as a submodule\n",
        "        self.model_part1 = model_part1\n",
        "        self.model_layer2 = model_layer2\n",
        "        self.model_layer3 = model_layer3\n",
        "        self.model_layer4 = model_layer4\n",
        "        self.model_part2 = model_part2\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through each part sequentially\n",
        "        x = self.model_part1(x)    # Initial ResNet layers\n",
        "        x = self.model_layer2(x)   # Custom block layer 2\n",
        "        x = self.model_layer3(x)   # Custom block layer 3\n",
        "        x = self.model_layer4(x)   # Custom block layer 4\n",
        "        x = self.model_part2(x)    # Final ResNet layers\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v1VZpcFnbigw"
      },
      "outputs": [],
      "source": [
        "model_part1 = ResNet_Part1()\n",
        "model_layer2 = CustomBlock(64, 128)\n",
        "model_layer3 = CustomBlock(128, 256)\n",
        "model_layer4 = CustomBlock(256, 512)\n",
        "model_part2 = ResNet_Part2()\n",
        "\n",
        "model = FullResNet(model_part1, model_layer2, model_layer3, model_layer4, model_part2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1jPgza41BhWA"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUbxW8Cg4KyZ",
        "outputId": "dd63f4fa-6955-4fbb-de6b-a113226dc505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FullResNet(\n",
            "  (model_part1): ResNet_Part1(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (3): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (5): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "    )\n",
            "  )\n",
            "  (model_layer2): CustomBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (gn2): GroupNorm(2, 128, eps=1e-05, affine=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    )\n",
            "  )\n",
            "  (model_layer3): CustomBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (gn2): GroupNorm(2, 256, eps=1e-05, affine=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    )\n",
            "  )\n",
            "  (model_layer4): CustomBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (gn2): GroupNorm(2, 512, eps=1e-05, affine=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    )\n",
            "  )\n",
            "  (model_part2): ResNet_Part2(\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n",
            "model_part1 ResNet_Part1(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (3): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (5): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (7): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "  )\n",
            ")\n",
            "model_part1.conv1 Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "model_part1.bn1 GroupNorm(32, 64, eps=1e-05, affine=True)\n",
            "model_part1.relu ReLU(inplace=True)\n",
            "model_part1.maxpool MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "model_part1.layer1 Sequential(\n",
            "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (1): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (3): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "  (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (5): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (7): GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            ")\n",
            "model_part1.layer1.0 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "model_part1.layer1.1 GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "model_part1.layer1.2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "model_part1.layer1.3 GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "model_part1.layer1.4 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "model_part1.layer1.5 GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "model_part1.layer1.6 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "model_part1.layer1.7 GroupNorm(2, 64, eps=1e-05, affine=True)\n",
            "model_layer2 CustomBlock(\n",
            "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (gn2): GroupNorm(2, 128, eps=1e-05, affine=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "  )\n",
            ")\n",
            "model_layer2.conv1 Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "model_layer2.relu ReLU(inplace=True)\n",
            "model_layer2.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "model_layer2.gn2 GroupNorm(2, 128, eps=1e-05, affine=True)\n",
            "model_layer2.downsample Sequential(\n",
            "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            ")\n",
            "model_layer2.downsample.0 Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "model_layer2.downsample.1 GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "model_layer3 CustomBlock(\n",
            "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (gn2): GroupNorm(2, 256, eps=1e-05, affine=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "  )\n",
            ")\n",
            "model_layer3.conv1 Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "model_layer3.relu ReLU(inplace=True)\n",
            "model_layer3.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "model_layer3.gn2 GroupNorm(2, 256, eps=1e-05, affine=True)\n",
            "model_layer3.downsample Sequential(\n",
            "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            ")\n",
            "model_layer3.downsample.0 Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "model_layer3.downsample.1 GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "model_layer4 CustomBlock(\n",
            "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (gn2): GroupNorm(2, 512, eps=1e-05, affine=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "  )\n",
            ")\n",
            "model_layer4.conv1 Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "model_layer4.relu ReLU(inplace=True)\n",
            "model_layer4.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "model_layer4.gn2 GroupNorm(2, 512, eps=1e-05, affine=True)\n",
            "model_layer4.downsample Sequential(\n",
            "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            ")\n",
            "model_layer4.downsample.0 Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "model_layer4.downsample.1 GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "model_part2 ResNet_Part2(\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=9, bias=True)\n",
            ")\n",
            "model_part2.avgpool AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "model_part2.fc Linear(in_features=512, out_features=9, bias=True)\n"
          ]
        }
      ],
      "source": [
        "for name, module in model.named_modules():\n",
        "    print(name, module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_first_trainable_layer_params(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            return name, param\n",
        "\n",
        "model = model\n",
        "name, param = get_first_trainable_layer_params(model)\n",
        "\n",
        "print(\"Name:\", name)\n",
        "print(\"Parameters:\", param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCrNu7OzdTjB",
        "outputId": "00f451c3-4f82-450a-f220-c2e33f3a4690"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: model_part1.conv1.weight\n",
            "Parameters: Parameter containing:\n",
            "tensor([[[[ 0.0189, -0.0196,  0.0226,  ...,  0.0352,  0.0196, -0.0095],\n",
            "          [-0.0667,  0.0188, -0.0730,  ...,  0.0055, -0.0181,  0.0674],\n",
            "          [ 0.0055,  0.0342,  0.0349,  ..., -0.0317,  0.0793, -0.0808],\n",
            "          ...,\n",
            "          [-0.0467, -0.0401, -0.0749,  ...,  0.0194,  0.0543,  0.0041],\n",
            "          [-0.0378,  0.0362, -0.0317,  ..., -0.0452, -0.0259, -0.0764],\n",
            "          [ 0.0352,  0.0321,  0.0164,  ...,  0.0350,  0.0036,  0.0087]],\n",
            "\n",
            "         [[ 0.0063,  0.0440,  0.0554,  ...,  0.0478, -0.0201, -0.0037],\n",
            "          [-0.0168,  0.0480,  0.0092,  ...,  0.0418, -0.0705,  0.0241],\n",
            "          [ 0.0793,  0.0733, -0.0013,  ..., -0.0774, -0.0263,  0.0402],\n",
            "          ...,\n",
            "          [-0.0771, -0.0177, -0.0521,  ..., -0.0101, -0.0821,  0.0200],\n",
            "          [ 0.0358, -0.0369, -0.0077,  ..., -0.0513, -0.0436, -0.0080],\n",
            "          [-0.0579,  0.0507,  0.0067,  ...,  0.0442, -0.0636, -0.0514]],\n",
            "\n",
            "         [[-0.0564, -0.0265, -0.0301,  ..., -0.0798,  0.0348,  0.0468],\n",
            "          [ 0.0261,  0.0524,  0.0620,  ...,  0.0125,  0.0765, -0.0598],\n",
            "          [-0.0367, -0.0043, -0.0513,  ..., -0.0122,  0.0735, -0.0052],\n",
            "          ...,\n",
            "          [-0.0294,  0.0561, -0.0802,  ..., -0.0559,  0.0257, -0.0337],\n",
            "          [-0.0736,  0.0320,  0.0417,  ..., -0.0707,  0.0803, -0.0062],\n",
            "          [-0.0785, -0.0124,  0.0539,  ..., -0.0009,  0.0581, -0.0753]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0572,  0.0819, -0.0502,  ..., -0.0133, -0.0696, -0.0007],\n",
            "          [-0.0276, -0.0704, -0.0601,  ...,  0.0765,  0.0295, -0.0549],\n",
            "          [ 0.0569,  0.0068, -0.0806,  ...,  0.0529, -0.0485, -0.0038],\n",
            "          ...,\n",
            "          [-0.0007, -0.0717,  0.0048,  ...,  0.0352, -0.0504, -0.0182],\n",
            "          [ 0.0330,  0.0224, -0.0775,  ..., -0.0292,  0.0303,  0.0737],\n",
            "          [ 0.0368,  0.0312, -0.0700,  ...,  0.0295, -0.0265, -0.0396]],\n",
            "\n",
            "         [[ 0.0234, -0.0447,  0.0335,  ..., -0.0544, -0.0514, -0.0343],\n",
            "          [-0.0706, -0.0095,  0.0514,  ..., -0.0266, -0.0102, -0.0359],\n",
            "          [-0.0666, -0.0225,  0.0057,  ..., -0.0618,  0.0241,  0.0121],\n",
            "          ...,\n",
            "          [-0.0079, -0.0373, -0.0348,  ...,  0.0431, -0.0424,  0.0033],\n",
            "          [ 0.0169,  0.0218, -0.0047,  ..., -0.0025, -0.0228, -0.0277],\n",
            "          [-0.0409, -0.0400, -0.0389,  ..., -0.0697, -0.0784,  0.0705]],\n",
            "\n",
            "         [[ 0.0296,  0.0456,  0.0360,  ..., -0.0518, -0.0562, -0.0052],\n",
            "          [ 0.0205, -0.0773, -0.0633,  ...,  0.0106,  0.0544,  0.0735],\n",
            "          [ 0.0501, -0.0175, -0.0367,  ...,  0.0671, -0.0791,  0.0221],\n",
            "          ...,\n",
            "          [ 0.0020, -0.0728, -0.0538,  ..., -0.0189, -0.0128,  0.0469],\n",
            "          [ 0.0310, -0.0175, -0.0271,  ...,  0.0425, -0.0580,  0.0256],\n",
            "          [-0.0150,  0.0642, -0.0526,  ...,  0.0095,  0.0024, -0.0355]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0824, -0.0706,  0.0447,  ..., -0.0190,  0.0292, -0.0139],\n",
            "          [-0.0620,  0.0546, -0.0216,  ...,  0.0808,  0.0799, -0.0614],\n",
            "          [-0.0216,  0.0467,  0.0511,  ..., -0.0600,  0.0346, -0.0563],\n",
            "          ...,\n",
            "          [ 0.0316,  0.0266,  0.0211,  ..., -0.0249, -0.0303,  0.0009],\n",
            "          [ 0.0739, -0.0599, -0.0011,  ...,  0.0464, -0.0817,  0.0034],\n",
            "          [ 0.0650, -0.0538,  0.0513,  ...,  0.0742, -0.0709,  0.0145]],\n",
            "\n",
            "         [[ 0.0599,  0.0597, -0.0412,  ...,  0.0018, -0.0399,  0.0520],\n",
            "          [-0.0428,  0.0087, -0.0722,  ...,  0.0723,  0.0437,  0.0349],\n",
            "          [-0.0485,  0.0705, -0.0411,  ..., -0.0681, -0.0407, -0.0251],\n",
            "          ...,\n",
            "          [-0.0498,  0.0512,  0.0115,  ...,  0.0393, -0.0556, -0.0485],\n",
            "          [-0.0080,  0.0541,  0.0421,  ..., -0.0582,  0.0277, -0.0060],\n",
            "          [ 0.0085,  0.0023, -0.0590,  ..., -0.0264, -0.0143,  0.0519]],\n",
            "\n",
            "         [[-0.0774,  0.0075,  0.0809,  ...,  0.0295,  0.0817,  0.0461],\n",
            "          [ 0.0442, -0.0311,  0.0339,  ...,  0.0798, -0.0795,  0.0424],\n",
            "          [-0.0505, -0.0743,  0.0769,  ..., -0.0455, -0.0774, -0.0165],\n",
            "          ...,\n",
            "          [ 0.0702, -0.0787,  0.0661,  ...,  0.0226, -0.0428,  0.0391],\n",
            "          [ 0.0101, -0.0203,  0.0779,  ...,  0.0712,  0.0555, -0.0127],\n",
            "          [-0.0257,  0.0660,  0.0330,  ..., -0.0637, -0.0807, -0.0348]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0339, -0.0733, -0.0404,  ...,  0.0238,  0.0343, -0.0154],\n",
            "          [-0.0382, -0.0014,  0.0537,  ..., -0.0372, -0.0502, -0.0413],\n",
            "          [-0.0408, -0.0398,  0.0564,  ...,  0.0003,  0.0291,  0.0063],\n",
            "          ...,\n",
            "          [-0.0597,  0.0439,  0.0138,  ...,  0.0714, -0.0083,  0.0372],\n",
            "          [-0.0774, -0.0109,  0.0679,  ...,  0.0642,  0.0008,  0.0034],\n",
            "          [-0.0475, -0.0759,  0.0044,  ...,  0.0166, -0.0443, -0.0189]],\n",
            "\n",
            "         [[-0.0643, -0.0234,  0.0656,  ..., -0.0333, -0.0772,  0.0460],\n",
            "          [ 0.0739,  0.0458,  0.0126,  ..., -0.0611,  0.0643,  0.0763],\n",
            "          [ 0.0497, -0.0205,  0.0473,  ..., -0.0692, -0.0780, -0.0053],\n",
            "          ...,\n",
            "          [-0.0232, -0.0766,  0.0751,  ...,  0.0731, -0.0603, -0.0228],\n",
            "          [-0.0209, -0.0469,  0.0657,  ...,  0.0158, -0.0611, -0.0441],\n",
            "          [ 0.0758,  0.0502, -0.0048,  ...,  0.0262, -0.0444,  0.0293]],\n",
            "\n",
            "         [[-0.0578, -0.0562, -0.0074,  ...,  0.0672, -0.0498, -0.0742],\n",
            "          [ 0.0187, -0.0660,  0.0141,  ..., -0.0068,  0.0396,  0.0599],\n",
            "          [-0.0070, -0.0125,  0.0749,  ..., -0.0469, -0.0770, -0.0639],\n",
            "          ...,\n",
            "          [ 0.0206,  0.0156, -0.0039,  ...,  0.0299,  0.0004,  0.0030],\n",
            "          [-0.0780, -0.0659,  0.0188,  ..., -0.0773, -0.0216,  0.0754],\n",
            "          [-0.0452, -0.0685,  0.0027,  ...,  0.0392,  0.0223,  0.0118]]],\n",
            "\n",
            "\n",
            "        [[[-0.0752,  0.0577,  0.0256,  ..., -0.0308, -0.0401,  0.0018],\n",
            "          [-0.0746, -0.0692,  0.0735,  ...,  0.0740,  0.0073,  0.0751],\n",
            "          [ 0.0445,  0.0672, -0.0325,  ...,  0.0757,  0.0753,  0.0580],\n",
            "          ...,\n",
            "          [-0.0345,  0.0171, -0.0788,  ..., -0.0301,  0.0349, -0.0814],\n",
            "          [ 0.0527, -0.0499, -0.0243,  ...,  0.0471, -0.0026, -0.0775],\n",
            "          [ 0.0115, -0.0117,  0.0150,  ..., -0.0790, -0.0632,  0.0467]],\n",
            "\n",
            "         [[-0.0056, -0.0127, -0.0265,  ...,  0.0500, -0.0013,  0.0374],\n",
            "          [-0.0165,  0.0167,  0.0047,  ..., -0.0640, -0.0463, -0.0621],\n",
            "          [-0.0163,  0.0791, -0.0535,  ..., -0.0164,  0.0098, -0.0377],\n",
            "          ...,\n",
            "          [ 0.0540,  0.0371, -0.0376,  ..., -0.0760, -0.0042,  0.0530],\n",
            "          [-0.0748, -0.0676,  0.0751,  ...,  0.0055, -0.0232, -0.0478],\n",
            "          [ 0.0180, -0.0593,  0.0220,  ..., -0.0618, -0.0269,  0.0702]],\n",
            "\n",
            "         [[-0.0189,  0.0718,  0.0221,  ..., -0.0130,  0.0632,  0.0362],\n",
            "          [ 0.0236,  0.0113,  0.0419,  ..., -0.0766, -0.0064,  0.0198],\n",
            "          [ 0.0696, -0.0157,  0.0376,  ...,  0.0777, -0.0031,  0.0636],\n",
            "          ...,\n",
            "          [-0.0661, -0.0558, -0.0064,  ...,  0.0742, -0.0654, -0.0113],\n",
            "          [ 0.0536,  0.0318, -0.0034,  ..., -0.0561,  0.0550,  0.0758],\n",
            "          [ 0.0228,  0.0177, -0.0064,  ...,  0.0145,  0.0410,  0.0223]]],\n",
            "\n",
            "\n",
            "        [[[-0.0247,  0.0742, -0.0747,  ...,  0.0302, -0.0134,  0.0472],\n",
            "          [-0.0796, -0.0338,  0.0406,  ...,  0.0106,  0.0170, -0.0491],\n",
            "          [-0.0477,  0.0538, -0.0198,  ..., -0.0336, -0.0681, -0.0718],\n",
            "          ...,\n",
            "          [ 0.0107, -0.0756, -0.0215,  ...,  0.0254, -0.0016,  0.0193],\n",
            "          [-0.0390,  0.0293, -0.0735,  ..., -0.0144,  0.0551, -0.0001],\n",
            "          [ 0.0414, -0.0762,  0.0590,  ..., -0.0541,  0.0172,  0.0573]],\n",
            "\n",
            "         [[-0.0527,  0.0388, -0.0021,  ...,  0.0294,  0.0074,  0.0696],\n",
            "          [-0.0769,  0.0655, -0.0600,  ...,  0.0379, -0.0539,  0.0365],\n",
            "          [-0.0796, -0.0258,  0.0202,  ..., -0.0260, -0.0497,  0.0122],\n",
            "          ...,\n",
            "          [ 0.0183, -0.0142,  0.0078,  ...,  0.0605, -0.0415, -0.0669],\n",
            "          [-0.0284,  0.0307, -0.0640,  ..., -0.0690,  0.0665,  0.0673],\n",
            "          [-0.0064,  0.0548, -0.0731,  ...,  0.0762,  0.0372,  0.0719]],\n",
            "\n",
            "         [[ 0.0134, -0.0396, -0.0529,  ...,  0.0477,  0.0114,  0.0454],\n",
            "          [ 0.0075,  0.0616,  0.0308,  ..., -0.0548, -0.0764,  0.0406],\n",
            "          [ 0.0743, -0.0610, -0.0196,  ..., -0.0706,  0.0763,  0.0139],\n",
            "          ...,\n",
            "          [-0.0580, -0.0215, -0.0279,  ..., -0.0732,  0.0305, -0.0390],\n",
            "          [-0.0357,  0.0736, -0.0043,  ...,  0.0557, -0.0349,  0.0735],\n",
            "          [-0.0136, -0.0221, -0.0204,  ...,  0.0159, -0.0534,  0.0786]]]],\n",
            "       device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "duFjbXRh3JNs"
      },
      "outputs": [],
      "source": [
        "opt = SGD(model.parameters(),lr = 1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ye6BgkMDUjEI"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 512\n",
        "MAX_PHYSICAL_BATCH_SIZE = 128\n",
        "n_acc_steps = BATCH_SIZE // MAX_PHYSICAL_BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "b9yP7oHXh1xf"
      },
      "outputs": [],
      "source": [
        "sigma=get_noise_multiplier(\n",
        "                target_epsilon = 4,\n",
        "                target_delta = 1e-5,\n",
        "                sample_rate = BATCH_SIZE/len(train_ds),\n",
        "                epochs = 50,\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72V6KwvckrSy",
        "outputId": "c6abf3ca-4e2d-4604-acc0-8bfbe325bfd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.909423828125\n"
          ]
        }
      ],
      "source": [
        "print(sigma)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "privacy_engine = PrivacyEngine(\n",
        "            model,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            max_grad_norm = 40,\n",
        "            sample_size=len(train_ds),\n",
        "            target_epsilon = 4,\n",
        "            target_delta = 1e-5,\n",
        "            epochs=50,\n",
        "            clipping_mode='ghost', #\"https://pytorch.org/blog/clipping-in-opacus/#:~:text=We%20introduce%20Fast%20Gradient%20Clipping,instantiating%20the%20per%2Dsample%20gradients.\"\n",
        "            clipping_style='all-layer',\n",
        "            origin_params= 'model_part1.conv1.weight',#['patch_embed.proj.bias'],\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysy7ceFqTx9-",
        "outputId": "9ae2e038-8308-4fe9-c98f-0cef7ab75ec9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using origin parameters for the ghost differentiation trick......\n",
            "Number of trainable components:  38 ; Number of trainable layers:  26\n",
            ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
            ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['model_part1.conv1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "privacy_engine.attach(opt)"
      ],
      "metadata": {
        "id": "ZfpqhA4yh1uO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LBddUUs5mfTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ce0bd0-cf31-4894-9d4d-99f6d0251de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:48<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 176 Train Loss: 2.261 | Acc: 12.293% (11063/89996)\n",
            "{'eps_rdp': 1.174846668203896, 'alpha_rdp': 8.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  2 176 Train Loss: 2.197 | Acc: 15.486% (13937/89996)\n",
            "{'eps_rdp': 1.2197288394607544, 'alpha_rdp': 8.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  3 176 Train Loss: 2.160 | Acc: 19.616% (17654/89996)\n",
            "{'eps_rdp': 1.2542737391422887, 'alpha_rdp': 8.3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  4 176 Train Loss: 2.134 | Acc: 21.708% (19536/89996)\n",
            "{'eps_rdp': 1.2843633380702666, 'alpha_rdp': 8.2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  5 176 Train Loss: 2.113 | Acc: 22.830% (20546/89996)\n",
            "{'eps_rdp': 1.311273311917243, 'alpha_rdp': 8.2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  6 176 Train Loss: 2.095 | Acc: 23.547% (21191/89996)\n",
            "{'eps_rdp': 1.336484269429437, 'alpha_rdp': 8.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  7 176 Train Loss: 2.079 | Acc: 24.369% (21931/89996)\n",
            "{'eps_rdp': 1.3600415178059193, 'alpha_rdp': 8.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  8 176 Train Loss: 2.064 | Acc: 25.012% (22510/89996)\n",
            "{'eps_rdp': 1.3835987661824016, 'alpha_rdp': 8.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  9 176 Train Loss: 2.049 | Acc: 25.587% (23027/89996)\n",
            "{'eps_rdp': 1.40499051573616, 'alpha_rdp': 8.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  10 176 Train Loss: 2.036 | Acc: 25.968% (23370/89996)\n",
            "{'eps_rdp': 1.426199554390674, 'alpha_rdp': 8.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  11 176 Train Loss: 2.022 | Acc: 26.295% (23664/89996)\n",
            "{'eps_rdp': 1.447408593045188, 'alpha_rdp': 8.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  12 176 Train Loss: 2.010 | Acc: 26.667% (23999/89996)\n",
            "{'eps_rdp': 1.4678910269681194, 'alpha_rdp': 7.9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  13 176 Train Loss: 1.998 | Acc: 27.047% (24341/89996)\n",
            "{'eps_rdp': 1.4874108419546428, 'alpha_rdp': 7.9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  14 176 Train Loss: 1.986 | Acc: 27.398% (24657/89996)\n",
            "{'eps_rdp': 1.506930656941166, 'alpha_rdp': 7.9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  15 176 Train Loss: 1.975 | Acc: 27.747% (24971/89996)\n",
            "{'eps_rdp': 1.5264504719276895, 'alpha_rdp': 7.9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  16 176 Train Loss: 1.964 | Acc: 28.010% (25208/89996)\n",
            "{'eps_rdp': 1.5459702869142127, 'alpha_rdp': 7.9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  17 176 Train Loss: 1.954 | Acc: 28.355% (25518/89996)\n",
            "{'eps_rdp': 1.5643642335066004, 'alpha_rdp': 7.8}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  18 176 Train Loss: 1.944 | Acc: 28.705% (25833/89996)\n",
            "{'eps_rdp': 1.5826327688254749, 'alpha_rdp': 7.8}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  19 176 Train Loss: 1.935 | Acc: 28.985% (26085/89996)\n",
            "{'eps_rdp': 1.6009013041443494, 'alpha_rdp': 7.8}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  20 176 Train Loss: 1.926 | Acc: 29.250% (26324/89996)\n",
            "{'eps_rdp': 1.619169839463224, 'alpha_rdp': 7.8}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  21 176 Train Loss: 1.917 | Acc: 29.467% (26519/89996)\n",
            "{'eps_rdp': 1.6374383747820984, 'alpha_rdp': 7.8}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  22 176 Train Loss: 1.909 | Acc: 29.735% (26760/89996)\n",
            "{'eps_rdp': 1.6554430631882502, 'alpha_rdp': 7.7}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:48<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  23 176 Train Loss: 1.902 | Acc: 29.937% (26942/89996)\n",
            "{'eps_rdp': 1.6727552691838463, 'alpha_rdp': 7.7}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  24 176 Train Loss: 1.895 | Acc: 30.164% (27146/89996)\n",
            "{'eps_rdp': 1.690067475179443, 'alpha_rdp': 7.7}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  25 176 Train Loss: 1.888 | Acc: 30.436% (27391/89996)\n",
            "{'eps_rdp': 1.707379681175039, 'alpha_rdp': 7.7}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  26 176 Train Loss: 1.881 | Acc: 30.722% (27649/89996)\n",
            "{'eps_rdp': 1.7246918871706354, 'alpha_rdp': 7.7}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  27 176 Train Loss: 1.875 | Acc: 31.032% (27928/89996)\n",
            "{'eps_rdp': 1.7420040931662317, 'alpha_rdp': 7.7}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:48<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  28 176 Train Loss: 1.868 | Acc: 31.253% (28126/89996)\n",
            "{'eps_rdp': 1.759316299161828, 'alpha_rdp': 7.7}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  29 176 Train Loss: 1.862 | Acc: 31.505% (28353/89996)\n",
            "{'eps_rdp': 1.7761696400089448, 'alpha_rdp': 7.6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  30 176 Train Loss: 1.857 | Acc: 31.778% (28599/89996)\n",
            "{'eps_rdp': 1.7927269083208386, 'alpha_rdp': 7.6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  31 176 Train Loss: 1.852 | Acc: 31.955% (28758/89996)\n",
            "{'eps_rdp': 1.8092841766327323, 'alpha_rdp': 7.6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  32 176 Train Loss: 1.846 | Acc: 32.186% (28966/89996)\n",
            "{'eps_rdp': 1.825841444944626, 'alpha_rdp': 7.6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  33 176 Train Loss: 1.841 | Acc: 32.396% (29155/89996)\n",
            "{'eps_rdp': 1.8423987132565198, 'alpha_rdp': 7.6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:48<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  34 176 Train Loss: 1.836 | Acc: 32.645% (29379/89996)\n",
            "{'eps_rdp': 1.8589559815684136, 'alpha_rdp': 7.6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  35 176 Train Loss: 1.831 | Acc: 32.898% (29607/89996)\n",
            "{'eps_rdp': 1.8755132498803073, 'alpha_rdp': 7.6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  36 176 Train Loss: 1.826 | Acc: 33.125% (29811/89996)\n",
            "{'eps_rdp': 1.8920382480831384, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  37 176 Train Loss: 1.822 | Acc: 33.364% (30026/89996)\n",
            "{'eps_rdp': 1.9079800500138084, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  38 176 Train Loss: 1.817 | Acc: 33.543% (30187/89996)\n",
            "{'eps_rdp': 1.9239218519444785, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  39 176 Train Loss: 1.813 | Acc: 33.728% (30354/89996)\n",
            "{'eps_rdp': 1.9398636538751486, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:48<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  40 176 Train Loss: 1.809 | Acc: 33.968% (30570/89996)\n",
            "{'eps_rdp': 1.9558054558058189, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  41 176 Train Loss: 1.804 | Acc: 34.162% (30744/89996)\n",
            "{'eps_rdp': 1.9717472577364892, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  42 176 Train Loss: 1.800 | Acc: 34.310% (30878/89996)\n",
            "{'eps_rdp': 1.9876890596671593, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  43 176 Train Loss: 1.796 | Acc: 34.545% (31089/89996)\n",
            "{'eps_rdp': 2.0036308615978293, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  44 176 Train Loss: 1.792 | Acc: 34.754% (31277/89996)\n",
            "{'eps_rdp': 2.0195726635284994, 'alpha_rdp': 7.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  45 176 Train Loss: 1.788 | Acc: 34.953% (31456/89996)\n",
            "{'eps_rdp': 2.035077032990021, 'alpha_rdp': 7.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  46 176 Train Loss: 1.785 | Acc: 35.165% (31647/89996)\n",
            "{'eps_rdp': 2.0505013816337048, 'alpha_rdp': 7.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:45<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  47 176 Train Loss: 1.781 | Acc: 35.333% (31798/89996)\n",
            "{'eps_rdp': 2.065925730277388, 'alpha_rdp': 7.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:47<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  48 176 Train Loss: 1.778 | Acc: 35.538% (31983/89996)\n",
            "{'eps_rdp': 2.081350078921071, 'alpha_rdp': 7.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  49 176 Train Loss: 1.774 | Acc: 35.716% (32143/89996)\n",
            "{'eps_rdp': 2.0967744275647546, 'alpha_rdp': 7.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:46<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  50 176 Train Loss: 1.770 | Acc: 35.820% (32237/89996)\n",
            "{'eps_rdp': 2.112198776208438, 'alpha_rdp': 7.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def train(epoch):\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(tqdm(train_dl)):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            if ((batch_idx + 1) % n_acc_steps == 0) or ((batch_idx + 1) == len(train_dl)):\n",
        "                opt.step()\n",
        "                opt.zero_grad()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        print('Epoch: ', epoch+1, len(train_dl), 'Train Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        print(privacy_engine.get_privacy_spent())\n",
        "\n",
        "def test(epoch):\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(tqdm(test_dl)):\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            print('Epoch: ', epoch+1, len(test_dl), 'Test Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "for epoch in range(50):\n",
        "        train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kTBAOHEWBF4",
        "outputId": "4afcf650-0197-4b07-de5a-6ddcf75e269a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:01<00:00,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  2 15 Test Loss: 1.703 | Acc: 42.479% (3050/7180)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "privacy_engine.get_privacy_spent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFo9Gk09sHM-",
        "outputId": "368cc7b7-6c1e-4e55-b3fd-28db1f25ce47"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eps_rdp': 2.112198776208438, 'alpha_rdp': 7.4}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"AWS_Fast_DP_deafult.pt\")"
      ],
      "metadata": {
        "id": "qHLnZKV3sOrQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJw2t5ZpYxgn",
        "outputId": "e0ebc785-4393-4390-e9c4-03dd75556960"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/                 \u001b[01;34mexamples\u001b[0m/         NOTICE.md         setup.py\n",
            "AWS_Fast_DP_deafult.pt  \u001b[01;34mfastDP\u001b[0m/           \u001b[01;34m__pycache__\u001b[0m/      THIRD-PARTY-NOTICES.txt\n",
            "CODE_OF_CONDUCT.md      \u001b[01;34mfastDP.egg-info\u001b[0m/  README.md\n",
            "CONTRIBUTING.md         LICENSE           requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qho-dw9ZZlOY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}